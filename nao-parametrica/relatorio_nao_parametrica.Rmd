---
title: "Testes de Aderência"
author: "Pedro Menezes de Araújo, Pedro Pires Costa"
date: "13 de julho de 2017"
output: pdf_document
number_sections: true
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


```

```{r echo=F, warning=F}
library(magrittr, warn.conflicts=F)
library(dplyr,warn.conflicts=F)
library(stringr,warn.conflicts = F)

n_interval <- function(x, inf, sup) {
  return(length(x[x>inf & x < sup]))
}

obs <- function(x, intervalos) {
  observados <- length(x[x<intervalos[1]])
  for(i in 1:(length(intervalos)-1)){
        observados <- c(observados, n_interval(x, intervalos[i], intervalos[i+1]))
  }
  observados <- c(observados, length(x[x > intervalos[length(intervalos)]]))
  observados
  
}

chisq.test <- function(x, dist='pnorm') {
  library(magrittr,warn.conflicts = F)
  if(dist=='pnorm'){
    if(length(x) == 10){
      intervalos=0
    }else{
      p <- 5/length(x)
      d <- seq(p, 0.5, by=p)
      intervalos <- c(qnorm(d, lower.tail=T), rev(-qnorm(d, lower.tail = T))) %>% unique()
      qui <- sum(((obs(x, intervalos) - 5)^2)/5)
      p.value <- pchisq(qui, df=length(x)-2, lower.tail = F)
    }
  }else if(dist == 'pexp'){
    p <- 5/length(x)
    d <- seq(p, 0.5, by=p)
    d_a <- d[-length(d)] + 0.5
    d <- c(d, d_a)
    intervalos <- qexp(d, rate=1)
    qui <- sum(((obs(x, intervalos) -5)^2)/5)
    p.value <- pchisq(qui, df=length(x)-1, lower.tail=F)
  }else if(dist=='punif'){
    #code uniforme
    p <- 5/length(x)
    d <- seq(p, 0.5, by=p)
    d_a <- d[-length(d)] + 0.5
    d <- c(d, d_a)
    intervalos <- qunif(d, 0, 1)
    qui <- sum(((obs(x, intervalos) -5)^2)/5)
    p.value <- pchisq(qui, df=length(x)-1, lower.tail=F)
  }
  resultado <- list(int = intervalos, d=d, p=p, obs = obs(x, intervalos),qui=qui,
                    p.value=p.value)
  return(resultado)
}

##normal
library(goftest)

comp <- function(r, p) {
  set.seed(1000)
  resultado <- list()
  testes <- c('chisq'= chisq.test, 'ks' = ks.test, 'cvm' = cvm.test)
  for(i in 1:3){
    n_n <- vector()
    for(n in c(20, 100, 500, 1000, 5000)){
      p.valor <- vector()
      for(experimento in 1:100){
        amostra <- eval(parse(text=r))(n)
        p.valor <- c(p.valor, testes[[i]](amostra, p)$p.value)
      }
      acertos <- length(p.valor[p.valor > 0.1])
      n_n <- c(n_n, acertos)
    }
    resultado[[names(testes[i])]] <- n_n
  }
  resultado
    
}
library(purrr,warn.conflicts = F)
library(tidyr,warn.conflicts = F)
library(ggplot2,warn.conflicts = F)
tidy <- function(df) {
    df_f <- gather(df %>% as.data.frame(), var, value, -n) %>% 
    unite('gp',var,n,remove=F) %>%
    separate(var,c('distri', 'teste')) %>% rename(acerto = value) %>%
    mutate(erro = 100 - acerto)
    df_f$n <- as.factor(df_f$n)
    return(df_f)
}

pp <- function(df, distribuicao, mode, titulo){
  mycol <- c('royalblue4', 'royalblue3', 'slategray2')
    pl <- df %>% filter(str_detect(distri, distribuicao)) %>%
    ggplot(aes_string('n',mode)) +
    geom_bar(stat='identity', position=position_dodge(), aes(fill=teste)) +
      scale_x_discrete(labels=rep(c(20, 100, 500, 1000, 5000),3)) +
      labs(x='Tamanho da amostra', y='Frequência de acertos', title=titulo) +
      scale_fill_manual(values=mycol) +
      theme_bw()
    return(pl)
}
##normal
normal <- map2(list('rnorm', 'rexp', 'runif'), list('pnorm'), comp)
names(normal) <- c('norm', 'exp', 'runif')
normal$n <- c(20, 100, 500, 1000, 5000)

p_n <- normal %>% tidy() %>% pp('norm','acerto', 'Ajuste normal com amostra normal')
p_n_e <- normal %>% tidy() %>% pp('exp', 'erro', 'Ajuste normal com amostra exponencial')
p_n_u <- normal %>% tidy() %>% pp('runif', 'erro', 'Ajuste normal com amostra uniforme')

#exponencial
exponencial <- map2(list('rnorm', 'rexp', 'runif'), list('pexp'), comp)
names(exponencial) <- c('norm', 'exp', 'runif')
exponencial$n <- c(20, 100, 500, 1000, 5000)

p_e <- exponencial %>% tidy %>% pp('exp','acerto', 'Ajuste exponencial com amostra exponencial')
p_e_n <- exponencial %>% tidy %>% pp('norm','erro' ,"Ajuste exponencial com amostra normal")
p_e_u <- exponencial %>% tidy %>% pp('runif','erro' ,'Ajuste exponencial com amostra uniforme')

#uniforme
uniforme <- map2(list('rnorm', 'rexp', 'runif'), list('punif'), comp)
names(uniforme) <- c('norm', 'exp', 'runif')
uniforme$n <- c(20, 100, 500, 1000, 5000)

p_u <- uniforme %>% tidy %>% pp('runif','acerto', 'Ajuste uniforme com amostra uniforme')
p_u_n <- uniforme %>% tidy %>% pp('norm','erro', 'Ajuste uniforme com amostra normal')
p_u_e <- uniforme %>% tidy %>% pp('exp','erro', 'Ajuste uniforme com amostra exponencial')


##multiplot
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid,warn.conflicts = F)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

#Introdução
<p>
Os testes de aderência (ou bondade de ajuste) são muito utilizados na rotina estatítica clássica. Eles servem para testar se uma determinada amostra aleatória é gerada por uma distribuição específica. São muito úteis, pois em boa parte dos casos não se sabe a distribuição de probabilidade da população no qual a amostra é proveniente. Tal informação é necessária, por exemplo, para decidir quais testes de hipóteses podem ser usados em análises posteriores.  
O presente trabalho tem por objetivo apresentar e comparar os teste de aderência Qui-quadrado, Kolomogorov-Smirnov e o teste de Cramér-von Mises através de simulações no ambiente R.
<p/>
<p>
Serão geradas 1000 amostras aleatórias com distribuição $Normal(0,1)$, $exp(1)$ e $U[0,1]$ de tamanhos, 10, 100, 1000, 10000, sendo aplicadas em cada teste com nível de significância $\alpha=0.1$, tendo em vista que nesse tipo deste $H_{0}$ é a hipótese do interesse (seguir a distribuição pré-especificada pelo pesquisador), com finalidade de comparar a taxa de acerto de cada teste.
</p>

#Teste Qui-quadrado
<p>
O teste qui-quadrado é bastante utilizado para testar a independência entre variáveis categóricas, mas pode ser adaptado para testar a aderência de amostra aleatória em relação a uma distribuição. O teste tenta captar a diferença entre valor observado e o valor esperado em intervalos *****. Uma restrição para o teste é que os valores esperados $e_{i,j}$ sejam maiores ou iguais a 5.

Seja $X_{1},...,X_{n}$ amostra aleatória de uma variável $X$ e $Y$ ****. As hipóetes para o teste são:
$$ H_{0}:X\: segue\: a\: distribuição\:Y $$
$$H_{1}: X \: não\: segue\:a\:distribuição\: Y$$
Com estatística de teste:
$$\frac{(o_{i} - e_{i})^2}{e_{i}} \sim \chi^2_{n-1}$$
Não há uma implementação exata da adaptação do teste qui-quadrado no R para a sua versão de aderência. No entanto, é possível implementa-la de forma autônoma. 
Para o caso contínuo, visando respeitar a condição da frequência esperada ser maior ou igual a 5, tempos:
$$e_{i}=p\:\cdotp n\Rightarrow p\:\cdot n \geq5\Rightarrow p\geq \frac{5}{n}$$
Optamos por manter a frequência observada igual a 5. Logo, iremos buscar por intervalos na   função densidade que compreendam o valor de probabilidade $$p=\frac{5}{n}$$  

</p>

#Teste Kolmogorov-Smirnov
<p>
O teste de Kolomogorov-Smirnov () é um teste que tem por finalidade comparar se duas amostras   aleatórias seguem a mesma distribuição de probabilidade. Ele é formulado através da função de   distribuição acumulada empírica, analisando a distância estre as duas funções. Uma das   aplicações do teste é como teste de aderência.   
Sejam $X_{1}, ...,X_{n}$ amostra aleatória com função distribuição acumulada $F$ e   $Y_{1},...Y_{m}$ amostra aleatória com função distribuição acumulada $G$. As hipóteses   utilizadas para a construção são: 
$$H_{0}:F=G$$
$$H_{1}: F \neq G $$
E a estatística de teste é:
$$D_{n,m} = max\{\mid F_{n}(x) - G_{m}(y)\mid\} $$
No R o teste pode ser feito usando a função __ks.test__. Um exemplo simples, onde queremos testar se a amostra segue uma distribuição $Normal(40, 2)$:
```{r echo=T, eval=T}
ks.test(rnorm(400, mean=40, sd=2), 'pnorm', 40, 2)
```
No teste acima a estatística $D_{400}$ obteve valor 0.047, e o p-valor 0.3234, logo, como o esperado, não rejeita-se a hipótese de normalidade. 
</p>
#Teste Cramér-von Mises
O teste de Cramér-von Mises ou cretério de Cramér-von Mises é uma alternativa ao teste de Kolmogorov-Smirnov. O teste também compara a igualdade de distribuições de probabilidae usando a função de distribuição empírica.
Para a versão de teste de aderência (também é possível comparar amostras) segue-se que:
Seja $x_{1}, ...,x_{n}$ amostra aleatória em ordem crescente com função de distribuição empírica $F_{n}$, a estatística do teste será: 
$$ T=n\omega^2=\frac{1}{12n} + \sum_{i=1}^{n}\bigg[\frac{2i-1}{2n} -F(x_{i})\bigg]^2$$
Sendo $\omega^2$ igual a:
$$\int_{-\infty}^{\infty} [F_{n}(x)-F^*(x)]^2dF^*(x)$$, aonde $F^*$ é a função de distribuição teórica. 
O p-valor pode é computado usando uma distribuição exata para essa estatística. 
Exemplo no R usando o pacote 'goftest':
```{r}
library(goftest)
cvm.test(rnorm(400), 'pnorm')
```
O teste retorna o valor de $\omega^2$ e o p-valor.

#Comparação entre os testes

```{r echo=F, fig.height=9}
multiplot(p_n, p_u, p_e)
```
```{r echo=F, fig.height=9}
multiplot(p_n_e, p_n_u, p_e_u)
```
```{r echo=F, fig.height=9}
multiplot(p_e_n, p_u_e, p_u_n)
```


#Conclusão






